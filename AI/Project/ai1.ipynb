{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> SPAM FILTER </h1>\n",
    "<p> The purpose of this assignment is to construct and evaluate one or more spam filters (classifiers). </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Imports </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data exploration and preparation </h1>\n",
    "<p> Our emails are divided in two different folders: spam and ham. We can say that in this way we have a labeled dataset. All we should do is to organize this dataset into a structure. But first, we should explore a bit the dataset.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#create two paths from where the emails will be read\n",
    "path_spam = os.getcwd() + '/spam'\n",
    "path_ham = os.getcwd() + '/ham'\n",
    "\n",
    "#create a list of tuples where a tuple will contain an email and a label\n",
    "#emails=[(email,label)]\n",
    "emails = []\n",
    "emails_original = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>If we have a look through emails we notice that most of the emails have an header which contains information about the email: when was received,from whom etc. I made two data structures, one which will contain the original emails and one which will contain only the content of the emails without the information from beginning. I made this because some words appears in most of the documents and they didn't help us so much to separate spam from ham. We are interested more in the content of the emails. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Reading and cleaning the dataset </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here I will try to make two data structures. One of them will contain the orginal emails and another which will contain only the content of the email.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these words represent the beginning of the line which should be deleted\n",
    "words_to_delete = ['From','Received','Return-Path','Delivered-To','Message-Id','Date','To','MIME-Version','Sender',\\\n",
    "                   'Errors-To','Reply-To','References','List-','Precedence','X-','Content-','\\t','Cc','User-Agent',\\\n",
    "                  'Message-ID','    ','Irish Linux Users','List maintainer','Organization','Thread-','Sent', 'Importance']\n",
    "\n",
    "#reading the spam emails from the directory\n",
    "#I label the spam email with one, because they are representing the positive class\n",
    "#Positive class is the class which we try to identify\n",
    "for filename in sorted(os.listdir(path_spam)):\n",
    "    file = open(\"spam/\"+filename,\"r\")\n",
    "    lines = file.readlines()\n",
    "    email_original = \"\"\n",
    "    email = \"\"\n",
    "    #append those lines which not begin with a word listed above\n",
    "    for line in lines:\n",
    "        if not any(word_to_delete in line for word_to_delete in words_to_delete): \n",
    "            email+=line\n",
    "        email_original+=line\n",
    "    #append the new email as a tuple to the list\n",
    "    emails.append((email,1))\n",
    "    #append the original emails as a tuple to the list\n",
    "    emails_original.append((email_original,1))\n",
    "    file.close()\n",
    "    \n",
    "#reading the ham emails from the directory\n",
    "##I label the ham email with zero, because they are representing the negative class\n",
    "for filename in sorted(os.listdir(path_ham)):\n",
    "    file = open(\"ham/\"+filename,\"r\")\n",
    "    lines = file.readlines()\n",
    "    email_original = \"\"\n",
    "    email = \"\"\n",
    "    #append those lines which not begin with a word listed above\n",
    "    for line in lines:\n",
    "        if not any(word_to_delete in line for word_to_delete in words_to_delete):\n",
    "            email+=line\n",
    "        email_original+=line\n",
    "    #append the new email as a tuple to the list\n",
    "    emails.append((email,0))\n",
    "    #append the original email as a tuple to the list\n",
    "    emails_original.append((email_original,0))\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Subject: [ILUG] STOP THE MLM INSANITY\\n\\nGreetings!\\n\\nYou are receiving this letter because you have expressed an interest in \\nreceiving information about online business opportunities. If this is \\nerroneous then please accept my most sincere apology. This is a one-time \\nmailing, so no removal is necessary.\\n\\nIf you\\'ve been burned, betrayed, and back-stabbed by multi-level marketing, \\nMLM, then please read this letter. It could be the most important one that \\nhas ever landed in your Inbox.\\n\\nMULTI-LEVEL MARKETING IS A HUGE MISTAKE FOR MOST PEOPLE\\n\\nMLM has failed to deliver on its promises for the past 50 years. The pursuit \\nof the \"MLM Dream\" has cost hundreds of thousands of people their friends, \\ntheir fortunes and their sacred honor. The fact is that MLM is fatally \\nflawed, meaning that it CANNOT work for most people.\\n\\nThe companies and the few who earn the big money in MLM are NOT going to \\ntell you the real story. FINALLY, there is someone who has the courage to \\ncut through the hype and lies and tell the TRUTH about MLM.\\n\\nHERE\\'S GOOD NEWS\\n\\nThere IS an alternative to MLM that WORKS, and works BIG! If you haven\\'t yet \\nabandoned your dreams, then you need to see this. Earning the kind of income \\nyou\\'ve dreamed about is easier than you think!\\n\\nWith your permission, I\\'d like to send you a brief letter that will tell you \\nWHY MLM doesn\\'t work for most people and will then introduce you to \\nsomething so new and refreshing that you\\'ll wonder why you haven\\'t heard of \\nthis before.\\n\\nI promise that there will be NO unwanted follow up, NO sales pitch, no one \\nwill call you, and your email address will only be used to send you the \\ninformation. Period.\\n\\n\"Send Info\" in the Subject box and hit Send. I\\'ll get the information to you \\nwithin 24 hours. Just look for the words MLM WALL OF SHAME in your Inbox.\\n\\nCordially,\\n\\nSiddhi\\n\\nP.S. Someone recently sent the letter to me and it has been the most \\neye-opening, financially beneficial information I have ever received. I \\nhonestly believe that you will feel the same way once you\\'ve read it. And \\nit\\'s FREE!\\n\\n\\n------------------------------------------------------------\\nThis email is NEVER sent unsolicited.  THIS IS NOT \"SPAM\". You are receiving \\nthis email because you EXPLICITLY signed yourself up to our list with our \\nonline signup form or through use of our FFA Links Page and E-MailDOM \\nsystems, which have EXPLICIT terms of use which state that through its use \\nyou agree to receive our emailings.  You may also be a member of a Altra \\nComputer Systems list or one of many numerous FREE Marketing Services and as \\nsuch you agreed when you signed up for such list that you would also be \\nreceiving this emailing.\\nDue to the above, this email message cannot be considered unsolicitated, or \\nspam.\\n-----------------------------------------------------------\\n\\n\\n\\n\\n-- \\nhttp://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\\n\\n\\n', 1)\n"
     ]
    }
   ],
   "source": [
    "#Let's have a look how emails look now\n",
    "print(emails[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('From ilug-admin@linux.ie  Tue Aug  6 11:51:02 2002\\nReturn-Path: <ilug-admin@linux.ie>\\nDelivered-To: yyyy@localhost.netnoteinc.com\\nReceived: from localhost (localhost [127.0.0.1])\\n\\tby phobos.labs.netnoteinc.com (Postfix) with ESMTP id 9E1F5441DD\\n\\tfor <jm@localhost>; Tue,  6 Aug 2002 06:48:09 -0400 (EDT)\\nReceived: from phobos [127.0.0.1]\\n\\tby localhost with IMAP (fetchmail-5.9.0)\\n\\tfor jm@localhost (single-drop); Tue, 06 Aug 2002 11:48:09 +0100 (IST)\\nReceived: from lugh.tuatha.org (root@lugh.tuatha.org [194.125.145.45]) by\\n    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g72LqWv13294 for\\n    <jm-ilug@jmason.org>; Fri, 2 Aug 2002 22:52:32 +0100\\nReceived: from lugh (root@localhost [127.0.0.1]) by lugh.tuatha.org\\n    (8.9.3/8.9.3) with ESMTP id WAA31224; Fri, 2 Aug 2002 22:50:17 +0100\\nReceived: from bettyjagessar.com (w142.z064000057.nyc-ny.dsl.cnc.net\\n    [64.0.57.142]) by lugh.tuatha.org (8.9.3/8.9.3) with ESMTP id WAA31201 for\\n    <ilug@linux.ie>; Fri, 2 Aug 2002 22:50:11 +0100\\nX-Authentication-Warning: lugh.tuatha.org: Host w142.z064000057.nyc-ny.dsl.cnc.net\\n    [64.0.57.142] claimed to be bettyjagessar.com\\nReceived: from 64.0.57.142 [202.63.165.34] by bettyjagessar.com\\n    (SMTPD32-7.06 EVAL) id A42A7FC01F2; Fri, 02 Aug 2002 02:18:18 -0400\\nMessage-Id: <1028311679.886@0.57.142>\\nDate: Fri, 02 Aug 2002 23:37:59 0530\\nTo: ilug@linux.ie\\nFrom: \"Start Now\" <startnow2002@hotmail.com>\\nMIME-Version: 1.0\\nContent-Type: text/plain; charset=\"US-ASCII\"; format=flowed\\nSubject: [ILUG] STOP THE MLM INSANITY\\nSender: ilug-admin@linux.ie\\nErrors-To: ilug-admin@linux.ie\\nX-Mailman-Version: 1.1\\nPrecedence: bulk\\nList-Id: Irish Linux Users\\' Group <ilug.linux.ie>\\nX-Beenthere: ilug@linux.ie\\n\\nGreetings!\\n\\nYou are receiving this letter because you have expressed an interest in \\nreceiving information about online business opportunities. If this is \\nerroneous then please accept my most sincere apology. This is a one-time \\nmailing, so no removal is necessary.\\n\\nIf you\\'ve been burned, betrayed, and back-stabbed by multi-level marketing, \\nMLM, then please read this letter. It could be the most important one that \\nhas ever landed in your Inbox.\\n\\nMULTI-LEVEL MARKETING IS A HUGE MISTAKE FOR MOST PEOPLE\\n\\nMLM has failed to deliver on its promises for the past 50 years. The pursuit \\nof the \"MLM Dream\" has cost hundreds of thousands of people their friends, \\ntheir fortunes and their sacred honor. The fact is that MLM is fatally \\nflawed, meaning that it CANNOT work for most people.\\n\\nThe companies and the few who earn the big money in MLM are NOT going to \\ntell you the real story. FINALLY, there is someone who has the courage to \\ncut through the hype and lies and tell the TRUTH about MLM.\\n\\nHERE\\'S GOOD NEWS\\n\\nThere IS an alternative to MLM that WORKS, and works BIG! If you haven\\'t yet \\nabandoned your dreams, then you need to see this. Earning the kind of income \\nyou\\'ve dreamed about is easier than you think!\\n\\nWith your permission, I\\'d like to send you a brief letter that will tell you \\nWHY MLM doesn\\'t work for most people and will then introduce you to \\nsomething so new and refreshing that you\\'ll wonder why you haven\\'t heard of \\nthis before.\\n\\nI promise that there will be NO unwanted follow up, NO sales pitch, no one \\nwill call you, and your email address will only be used to send you the \\ninformation. Period.\\n\\nTo receive this free, life-changing information, simply click Reply, type \\n\"Send Info\" in the Subject box and hit Send. I\\'ll get the information to you \\nwithin 24 hours. Just look for the words MLM WALL OF SHAME in your Inbox.\\n\\nCordially,\\n\\nSiddhi\\n\\nP.S. Someone recently sent the letter to me and it has been the most \\neye-opening, financially beneficial information I have ever received. I \\nhonestly believe that you will feel the same way once you\\'ve read it. And \\nit\\'s FREE!\\n\\n\\n------------------------------------------------------------\\nThis email is NEVER sent unsolicited.  THIS IS NOT \"SPAM\". You are receiving \\nthis email because you EXPLICITLY signed yourself up to our list with our \\nonline signup form or through use of our FFA Links Page and E-MailDOM \\nsystems, which have EXPLICIT terms of use which state that through its use \\nyou agree to receive our emailings.  You may also be a member of a Altra \\nComputer Systems list or one of many numerous FREE Marketing Services and as \\nsuch you agreed when you signed up for such list that you would also be \\nreceiving this emailing.\\nDue to the above, this email message cannot be considered unsolicitated, or \\nspam.\\n-----------------------------------------------------------\\n\\n\\n\\n\\n-- \\nIrish Linux Users\\' Group: ilug@linux.ie\\nhttp://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\\nList maintainer: listmaster@linux.ie\\n\\n\\n', 1)\n"
     ]
    }
   ],
   "source": [
    "#Let's have a look at the original mail\n",
    "print(emails_original[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: [ILUG] STOP THE MLM INSANITY\\n\\nGreet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: Real Protection, Stun Guns!  Free Shi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: New Improved Fat Burners, Now With TV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: New Improved Fat Burners, Now With TV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: Never Repay Cash Grants, $500 - $50,0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(SMTPD32-7.10) id A2E8640144; Tue, 23 Jul 20...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Subject: New Product Announcement\\n\\nNEW PRODU...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Subject: FW:\\n\\n\\n&lt;HTML&gt;\\n&lt;BODY bgColor=3D#C0C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Subject: [SA] URGENT HELP..............\\n\\n--=...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Subject: Your Agent in Saudi Arabia.\\n\\n \\n\\nC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Subject: $$$$$$For your satellite system$$$$$$...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Subject: $$$$$$For your satellite system$$$$$$...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Subject: great rates for bad credit 3316118654...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Subject: Software that helps you remove negati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Subject: ****Already own a satellite?  Need a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Subject: Sun Hardware 50% off list price\\n\\n\\n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Subject: free satellite\\n\\nRECIEVE ALL CHANNEL...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Subject: Join Focus Groups to earn money\\n\\nTh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Subject: more site sales 542718131097665444333...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Subject: Porn P.O.: Your 10 free pictures are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Subject: Undeliverable: Home Based Business fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Subject: Press Release\\n\\nThis is a multi-part...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Subject: Cheap FLAT RATE InState, USA, Worldwi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Subject: Proposal for cooperation\\n\\nHello. I ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Subject: Thank You So Much 126432211111\\n\\n***...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Subject: Traderlist.com being shut down due to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Subject: Brand Name Product Business\\n\\nDear S...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\\nThis is a multi-part message in MIME format....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Subject: Be First...It\"s Your Turn...Don't Mis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Subject: ADV: Low Cost Life Insurance -- FREE ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>Subject: Personalize your Palm OS device\\n\\n--...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2869</th>\n",
       "      <td>Subject: [MLB-WIRELESS] FW: Cisco Wireless LAN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>Subject: AOL Keyword: Fraud Probe\\n\\nThis is a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>\\n&lt;html&gt;\\n&lt;head&gt;&lt;base href=\"http://story.news....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>Subject: [ILUG-Social] Re: Important - reenact...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>Subject: Market Can't Find Its Bottom With Bot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>Subject: Red Hat Linux 8.0 now available on Re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>Subject: (SPAM? 08.00) example.sourceforge.net...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>Subject: updated weblogs from blo.gs\\n\\nchange...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>Subject: MEDIA: spamNEWS Digest September 30 -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>Subject: testing for taint.org, part 2\\n\\ntopi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>Subject: Apt repository authentication: it's t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>Subject: Re: RedHat 8.0 and his own freetype\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>Subject: Quicker and easier shopping with Tesc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>Subject: Christmas is coming to all Ryanair pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>Subject: HTTP: The Definitive Guide\\n\\n\"HTTP: ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>Subject: Try our new Apparel store and get a 3...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>Subject: iSilo announcements (November 8, 2002...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>Subject: EFFector 15.35: ALERT UPDATE: Urge Yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>\\nThis is a multi-part message in MIME format....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>Subject: Re: [Razor-users] razor-revoke, trust...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>Subject: CuteFTP Pro 3.0 Released!\\n\\nThis is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>Subject: Software you can be thankful for\\n\\n-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>Subject: More Freebies with Ryanair.com\\n\\n\\nW...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>Subject: Cost price Guinness, Budweiser and se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>Subject: Apple Store eNews : November 2002\\n\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>Subject: IMHO 1.10 - Chomsky, Fashion, and Seg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>Subject: Neat Net Tricks Standard Issue #138, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>Subject: CuteFTP exclusive: OmniPage Pro with ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>Subject: FC Sporadic for Wednesday, October 30...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2898 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  email  label\n",
       "0     Subject: [ILUG] STOP THE MLM INSANITY\\n\\nGreet...      1\n",
       "1     Subject: Real Protection, Stun Guns!  Free Shi...      1\n",
       "2     Subject: New Improved Fat Burners, Now With TV...      1\n",
       "3     Subject: New Improved Fat Burners, Now With TV...      1\n",
       "4     Subject: Never Repay Cash Grants, $500 - $50,0...      1\n",
       "5       (SMTPD32-7.10) id A2E8640144; Tue, 23 Jul 20...      1\n",
       "6     Subject: New Product Announcement\\n\\nNEW PRODU...      1\n",
       "7     Subject: FW:\\n\\n\\n<HTML>\\n<BODY bgColor=3D#C0C...      1\n",
       "8     Subject: [SA] URGENT HELP..............\\n\\n--=...      1\n",
       "9     Subject: Your Agent in Saudi Arabia.\\n\\n \\n\\nC...      1\n",
       "10    Subject: $$$$$$For your satellite system$$$$$$...      1\n",
       "11    Subject: $$$$$$For your satellite system$$$$$$...      1\n",
       "12    Subject: great rates for bad credit 3316118654...      1\n",
       "13    Subject: Software that helps you remove negati...      1\n",
       "14    Subject: ****Already own a satellite?  Need a ...      1\n",
       "15    Subject: Sun Hardware 50% off list price\\n\\n\\n...      1\n",
       "16    Subject: free satellite\\n\\nRECIEVE ALL CHANNEL...      1\n",
       "17    Subject: Join Focus Groups to earn money\\n\\nTh...      1\n",
       "18    Subject: more site sales 542718131097665444333...      1\n",
       "19    Subject: Porn P.O.: Your 10 free pictures are ...      1\n",
       "20    Subject: Undeliverable: Home Based Business fo...      1\n",
       "21    Subject: Press Release\\n\\nThis is a multi-part...      1\n",
       "22    Subject: Cheap FLAT RATE InState, USA, Worldwi...      1\n",
       "23    Subject: Proposal for cooperation\\n\\nHello. I ...      1\n",
       "24    Subject: Thank You So Much 126432211111\\n\\n***...      1\n",
       "25    Subject: Traderlist.com being shut down due to...      1\n",
       "26    Subject: Brand Name Product Business\\n\\nDear S...      1\n",
       "27    \\nThis is a multi-part message in MIME format....      1\n",
       "28    Subject: Be First...It\"s Your Turn...Don't Mis...      1\n",
       "29    Subject: ADV: Low Cost Life Insurance -- FREE ...      1\n",
       "...                                                 ...    ...\n",
       "2868  Subject: Personalize your Palm OS device\\n\\n--...      0\n",
       "2869  Subject: [MLB-WIRELESS] FW: Cisco Wireless LAN...      0\n",
       "2870  Subject: AOL Keyword: Fraud Probe\\n\\nThis is a...      0\n",
       "2871  \\n<html>\\n<head><base href=\"http://story.news....      0\n",
       "2872  Subject: [ILUG-Social] Re: Important - reenact...      0\n",
       "2873  Subject: Market Can't Find Its Bottom With Bot...      0\n",
       "2874  Subject: Red Hat Linux 8.0 now available on Re...      0\n",
       "2875  Subject: (SPAM? 08.00) example.sourceforge.net...      0\n",
       "2876  Subject: updated weblogs from blo.gs\\n\\nchange...      0\n",
       "2877  Subject: MEDIA: spamNEWS Digest September 30 -...      0\n",
       "2878  Subject: testing for taint.org, part 2\\n\\ntopi...      0\n",
       "2879  Subject: Apt repository authentication: it's t...      0\n",
       "2880  Subject: Re: RedHat 8.0 and his own freetype\\n...      0\n",
       "2881  Subject: Quicker and easier shopping with Tesc...      0\n",
       "2882  Subject: Christmas is coming to all Ryanair pa...      0\n",
       "2883  Subject: HTTP: The Definitive Guide\\n\\n\"HTTP: ...      0\n",
       "2884  Subject: Try our new Apparel store and get a 3...      0\n",
       "2885  Subject: iSilo announcements (November 8, 2002...      0\n",
       "2886  Subject: EFFector 15.35: ALERT UPDATE: Urge Yo...      0\n",
       "2887  \\nThis is a multi-part message in MIME format....      0\n",
       "2888  Subject: Re: [Razor-users] razor-revoke, trust...      0\n",
       "2889  Subject: CuteFTP Pro 3.0 Released!\\n\\nThis is ...      0\n",
       "2890  Subject: Software you can be thankful for\\n\\n-...      0\n",
       "2891  Subject: More Freebies with Ryanair.com\\n\\n\\nW...      0\n",
       "2892  Subject: Cost price Guinness, Budweiser and se...      0\n",
       "2893  Subject: Apple Store eNews : November 2002\\n\\n...      0\n",
       "2894  Subject: IMHO 1.10 - Chomsky, Fashion, and Seg...      0\n",
       "2895  Subject: Neat Net Tricks Standard Issue #138, ...      0\n",
       "2896  Subject: CuteFTP exclusive: OmniPage Pro with ...      0\n",
       "2897  Subject: FC Sporadic for Wednesday, October 30...      0\n",
       "\n",
       "[2898 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build a dataframe of emails \n",
    "#The purpose is to work with numpy arrays\n",
    "labels = ['email','label']\n",
    "df = pd.DataFrame.from_records(emails, columns=labels)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As you can notice I kept the subject of email because it can offer us information about the content.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From ilug-admin@linux.ie  Tue Aug  6 11:51:02 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From lmrn@mailexcite.com  Mon Jun 24 17:03:24 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From amknight@mailexcite.com  Mon Jun 24 17:03...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From jordan23@mailexcite.com  Mon Jun 24 17:04...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From merchantsworld2001@juno.com  Tue Aug  6 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Received: from hq.pro-ns.net (localhost [127.0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>From sales@outsrc-em.com  Mon Jun 24 17:53:15 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>From ormlh@imail.ru  Sun Jul 15 04:56:31 2001\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>From spamassassin-sightings-admin@lists.source...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>From sathar@amtelsa.com  Mon Jun 24 17:40:14 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>From fork-admin@xent.com  Tue Jul 30 07:19:04 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>From fork-admin@xent.com  Tue Jul 30 19:22:12 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>From mrmerrch331611@aol.com  Mon Jun 24 17:02:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>From liuj7@say-mail.com  Mon Jun 24 17:40:47 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>From fork-admin@xent.com  Thu Aug  1 21:37:35 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>From hpr-2@solarisexpert.com  Mon Jun 24 17:41...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>From fork-admin@xent.com  Thu Aug  1 01:25:01 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>From register@alacarteresearch.com  Mon Jun 24...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>From dennisd542718@yahoo.com  Mon Jun 24 17:52...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>From admin@pornpo.com  Mon Jun 24 17:40:45 200...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>From postmaster@tfi.kpn.com  Mon Jun 24 17:40:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>From ardi@attbi.com  Mon Jun 24 17:40:43 2002\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>From myron@hotmail.com  Mon Jun 24 17:40:38 20...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>From oksana@antee.com  Mon Jun 24 17:40:25 200...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>From director126432@usahelp.com  Mon Jun 24 17...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>From mccarts@mindspring.com  Mon Jun 24 17:42:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>From Union@dogma.slashnull.org  Mon Jun 24 17:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>From tba@insurancemail.net  Mon Jun 24 17:42:5...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>From wrJerry@yahoo.com  Mon Jun 24 17:43:12 20...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>From lowerpymt@hey11.heyyy.com  Mon Jun 24 17:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>From champion@handango.com  Fri Sep 20 17:57:5...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2869</th>\n",
       "      <td>From owner-melbwireless@wireless.org.au  Thu S...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>From guterman@mediaunspun.imakenews.net  Thu S...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>From fork-admin@xent.com  Mon Sep 30 13:53:26 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>From social-admin@linux.ie  Mon Sep 30 13:39:5...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>From guterman@mediaunspun.imakenews.net  Tue O...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>From dev-null@rhn.redhat.com  Tue Oct  1 21:09...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>Return-Path: &lt;test-admin@example.sourceforge.n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>From webmaster-bounce-571-2c9cb1de22e9da153a5e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>From spam-request@z1.example.com  Sat Oct  5 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>From qtopic+admin@quicktopic.com  Sun Oct  6 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>From rpm-list-admin@freshrpms.net  Wed Oct  9 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>From rpm-list-admin@freshrpms.net  Wed Oct  9 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>From tesco.ie@crrvja.cjsias.uhbeqs.bounce.12hs...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>From bounce-customers-949326@mail.ryanairmail....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>From bounce-ora_webprog-1083425@newsletter.ore...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>From ems+P8T5PED6GPLZ4A@bounces.amazon.com  Sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>From isilo@phish.siteprotect.com  Sat Nov  9 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>From alerts@action.eff.org  Sun Nov 10 17:19:1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>From facelist@espial.com  Tue Nov 12 23:33:43 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>From razor-users-admin@lists.sourceforge.net  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>From XLZ8637804.news@mail3.globalscape.com  Fr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>From champion@handango.com  Fri Nov 15 19:42:2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>From bounce-customers-949326@mail.ryanairmail....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>From tesco.ie@ctejmi.cjsias.bwmmxq.bounce.12hs...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>From senews-nov@euromailer.lists.apple.com  Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>From imho@eircom.net  Thu Nov 28 11:41:56 2002...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>From bounce-neatnettricks-2424157@silver.lyris...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>From owner-nolist-seg25187*jm-cuteftp**JMASON*...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>From sporadic@fuckedcompany.com  Wed Oct 30 21...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2898 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  email  label\n",
       "0     From ilug-admin@linux.ie  Tue Aug  6 11:51:02 ...      1\n",
       "1     From lmrn@mailexcite.com  Mon Jun 24 17:03:24 ...      1\n",
       "2     From amknight@mailexcite.com  Mon Jun 24 17:03...      1\n",
       "3     From jordan23@mailexcite.com  Mon Jun 24 17:04...      1\n",
       "4     From merchantsworld2001@juno.com  Tue Aug  6 1...      1\n",
       "5     Received: from hq.pro-ns.net (localhost [127.0...      1\n",
       "6     From sales@outsrc-em.com  Mon Jun 24 17:53:15 ...      1\n",
       "7     From ormlh@imail.ru  Sun Jul 15 04:56:31 2001\\...      1\n",
       "8     From spamassassin-sightings-admin@lists.source...      1\n",
       "9     From sathar@amtelsa.com  Mon Jun 24 17:40:14 2...      1\n",
       "10    From fork-admin@xent.com  Tue Jul 30 07:19:04 ...      1\n",
       "11    From fork-admin@xent.com  Tue Jul 30 19:22:12 ...      1\n",
       "12    From mrmerrch331611@aol.com  Mon Jun 24 17:02:...      1\n",
       "13    From liuj7@say-mail.com  Mon Jun 24 17:40:47 2...      1\n",
       "14    From fork-admin@xent.com  Thu Aug  1 21:37:35 ...      1\n",
       "15    From hpr-2@solarisexpert.com  Mon Jun 24 17:41...      1\n",
       "16    From fork-admin@xent.com  Thu Aug  1 01:25:01 ...      1\n",
       "17    From register@alacarteresearch.com  Mon Jun 24...      1\n",
       "18    From dennisd542718@yahoo.com  Mon Jun 24 17:52...      1\n",
       "19    From admin@pornpo.com  Mon Jun 24 17:40:45 200...      1\n",
       "20    From postmaster@tfi.kpn.com  Mon Jun 24 17:40:...      1\n",
       "21    From ardi@attbi.com  Mon Jun 24 17:40:43 2002\\...      1\n",
       "22    From myron@hotmail.com  Mon Jun 24 17:40:38 20...      1\n",
       "23    From oksana@antee.com  Mon Jun 24 17:40:25 200...      1\n",
       "24    From director126432@usahelp.com  Mon Jun 24 17...      1\n",
       "25    From mccarts@mindspring.com  Mon Jun 24 17:42:...      1\n",
       "26    From Union@dogma.slashnull.org  Mon Jun 24 17:...      1\n",
       "27    From tba@insurancemail.net  Mon Jun 24 17:42:5...      1\n",
       "28    From wrJerry@yahoo.com  Mon Jun 24 17:43:12 20...      1\n",
       "29    From lowerpymt@hey11.heyyy.com  Mon Jun 24 17:...      1\n",
       "...                                                 ...    ...\n",
       "2868  From champion@handango.com  Fri Sep 20 17:57:5...      0\n",
       "2869  From owner-melbwireless@wireless.org.au  Thu S...      0\n",
       "2870  From guterman@mediaunspun.imakenews.net  Thu S...      0\n",
       "2871  From fork-admin@xent.com  Mon Sep 30 13:53:26 ...      0\n",
       "2872  From social-admin@linux.ie  Mon Sep 30 13:39:5...      0\n",
       "2873  From guterman@mediaunspun.imakenews.net  Tue O...      0\n",
       "2874  From dev-null@rhn.redhat.com  Tue Oct  1 21:09...      0\n",
       "2875  Return-Path: <test-admin@example.sourceforge.n...      0\n",
       "2876  From webmaster-bounce-571-2c9cb1de22e9da153a5e...      0\n",
       "2877  From spam-request@z1.example.com  Sat Oct  5 1...      0\n",
       "2878  From qtopic+admin@quicktopic.com  Sun Oct  6 2...      0\n",
       "2879  From rpm-list-admin@freshrpms.net  Wed Oct  9 ...      0\n",
       "2880  From rpm-list-admin@freshrpms.net  Wed Oct  9 ...      0\n",
       "2881  From tesco.ie@crrvja.cjsias.uhbeqs.bounce.12hs...      0\n",
       "2882  From bounce-customers-949326@mail.ryanairmail....      0\n",
       "2883  From bounce-ora_webprog-1083425@newsletter.ore...      0\n",
       "2884  From ems+P8T5PED6GPLZ4A@bounces.amazon.com  Sa...      0\n",
       "2885  From isilo@phish.siteprotect.com  Sat Nov  9 1...      0\n",
       "2886  From alerts@action.eff.org  Sun Nov 10 17:19:1...      0\n",
       "2887  From facelist@espial.com  Tue Nov 12 23:33:43 ...      0\n",
       "2888  From razor-users-admin@lists.sourceforge.net  ...      0\n",
       "2889  From XLZ8637804.news@mail3.globalscape.com  Fr...      0\n",
       "2890  From champion@handango.com  Fri Nov 15 19:42:2...      0\n",
       "2891  From bounce-customers-949326@mail.ryanairmail....      0\n",
       "2892  From tesco.ie@ctejmi.cjsias.bwmmxq.bounce.12hs...      0\n",
       "2893  From senews-nov@euromailer.lists.apple.com  Th...      0\n",
       "2894  From imho@eircom.net  Thu Nov 28 11:41:56 2002...      0\n",
       "2895  From bounce-neatnettricks-2424157@silver.lyris...      0\n",
       "2896  From owner-nolist-seg25187*jm-cuteftp**JMASON*...      0\n",
       "2897  From sporadic@fuckedcompany.com  Wed Oct 30 21...      0\n",
       "\n",
       "[2898 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build a dataframe of original emails\n",
    "labels = ['email','label']\n",
    "df_original = pd.DataFrame.from_records(emails_original, columns=labels)\n",
    "df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2898</td>\n",
       "      <td>2898.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2825</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>\\n\\nHello I am your hot lil horny toy.\\n\\n\\n\\n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.430642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    email        label\n",
       "count                                                2898  2898.000000\n",
       "unique                                               2825          NaN\n",
       "top     \\n\\nHello I am your hot lil horny toy.\\n\\n\\n\\n...          NaN\n",
       "freq                                                    7          NaN\n",
       "mean                                                  NaN     0.430642\n",
       "std                                                   NaN     0.495252\n",
       "min                                                   NaN     0.000000\n",
       "25%                                                   NaN     0.000000\n",
       "50%                                                   NaN     0.000000\n",
       "75%                                                   NaN     1.000000\n",
       "max                                                   NaN     1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's look more detailed to emails\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can notice that when I build the dataframe I put the emails in order so I should shuffle it.\n",
    "df = df.take(np.random.permutation(len(df)))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df_original = df_original.take(np.random.permutation(len(df_original)))\n",
    "df_original.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the actual values\n",
    "y = df['label'].values\n",
    "y_original = df_original['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the data which will be processed\n",
    "X = df['email'].values\n",
    "X_original = df_original['email'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Classifiers </h1>\n",
    "<p>Here I begin to create different pipelines. All I try to do is to play with different parameters and compare between these pipelines.</p>\n",
    "<p> I have decided to use K-Fold validation stratified because it divides the examples proportional into folds. For the value of K I use 10 because are 2898 emails which means that in every fold it will be aproximately 289, which means that we have plenty examples to train and test the data. </p>\n",
    "<p>To compare them I used also different performance measures.</p>\n",
    "<ul>\n",
    "    <li>Accuracy: the ratio of the number of correct predictions to number of predictions made.I used this because because measures the overall corectness of the classifier.</li>\n",
    "    <li>Precision: the fraction of positive predictions that are correct. In our case the fraction of messages classified as spam that are actually spam.</li>\n",
    "    <li>Recall: represents the ability of classifier to find all the positive examples. In our case is the fraction of spam messages that were truly classified as spam.</li>\n",
    "    <li>F1: represents the weighted average of the precison and recall scores. It penalizes classifiers with imbalanced precision and recall scores.</li>\n",
    "     <li>Confusion matrix. I used this to visualize better the number of correct and incorrect predictions made.</li>\n",
    "</ul>\n",
    "<p> Also, I have decided to use only these combinations for pipelines: TfidfVectorizer + LogisticRegression and\n",
    "CountVectorizer + LogisticRegression because I want to demonstrate that they can be improved by playing only with their parameters. </p>\n",
    "\n",
    "<p> Source for the performance measures: Mastering Machine Learning with scikit-learn, author Gavin Hackeling and <a href = \"http://scikit-learn.org/stable/modules/model_evaluation.html\"> sklearn documentation. </a> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Also, we can consider the Majority-Class Classifier which always predicts the majority class. </p>\n",
    "<p> I used it as a baseline that I can compare against when evaluating a classifier. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the majority classifier \n",
    "emails_pipeline_dummy = Pipeline([(\"vectorizer\", TfidfVectorizer(stop_words = 'english')),\n",
    "                           (\"estimator\", DummyClassifier(strategy=\"most_frequent\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56935926500417611"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(emails_pipeline_dummy, X, y, scoring='accuracy', cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TfidVectorizer pipelines</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the pipeline for the original emails\n",
    "emails_pipeline_original = Pipeline([(\"vectorizer\", TfidfVectorizer()),\n",
    "                           (\"estimator\", LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.956531440162\n",
      "Precision score: 0.955034819542\n",
      "Recall score: 0.943948387097\n",
      "F1 score: 0.949229720177\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_original, X_original, y_original, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_original, X_original, y_original, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_original, X_original, y_original, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_original, X_original, y_original, scoring='f1', cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1594,   56],\n",
       "       [  70, 1178]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_original, X_original, y_original, cv=10)\n",
    "confusion_matrix(y_original, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the pipeline with emails after I deleted the lines from beginning\n",
    "emails_pipeline_simple = Pipeline([(\"vectorizer\", TfidfVectorizer()),\n",
    "                           (\"estimator\", LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.966525474287\n",
      "Precision score: 0.963241687227\n",
      "Recall score: 0.959129032258\n",
      "F1 score: 0.961068666175\n"
     ]
    }
   ],
   "source": [
    "#Performance measures\n",
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_simple, X, y, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_simple, X, y, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_simple, X, y, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_simple, X, y, scoring='f1', cv=10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1604,   46],\n",
       "       [  51, 1197]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_simple, X, y, cv=10)\n",
    "confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> As we can see, if you delete the information from the beginning we will obtain e better result. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>I take a look of TfidfVectorizer and Logistic Regression parameters.\n",
    "   Here are the links.\n",
    "   <a href =\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\">Logistic Regression</a>\n",
    "   <a href =\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">TfidVectorizer</a>\n",
    "</p>\n",
    "<p> I tried to understand what are the roles of these parameters and I found interesting things which make my classifier better. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discard stop-words:common words such a, as, the etc. which doesn' t help us for spam detection\n",
    "emails_pipeline_sw = Pipeline([(\"vectorizer\", TfidfVectorizer(stop_words='english')),\n",
    "                           (\"estimator\", LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.958933301515\n",
      "Precision score: 0.963231946437\n",
      "Recall score: 0.940696774194\n",
      "F1 score: 0.951752306589\n"
     ]
    }
   ],
   "source": [
    "#Performance measures\n",
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_sw, X, y, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_sw, X, y, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_sw, X, y, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_sw, X, y, scoring='f1', cv=10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1605,   45],\n",
       "       [  74, 1174]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_sw, X, y, cv=10)\n",
    "confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As we can notice, the number of true negatives it doesn't change from the previous, but it decreases the number of true positives and it increses the number of false negatives. This means that the classifier predicts more hams as spams which is not good for a spam filter(it must be possible that an important email to be predicted as spam).</p>\n",
    "<p>Now, let's try to improve this.</p>\n",
    "<p>Let's look at the other parameters.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's change the entropy. As default is liblinear algorithm.\n",
    "emails_pipeline_ncg = Pipeline([(\"vectorizer\", TfidfVectorizer(stop_words = 'english')),\n",
    "                           (\"estimator\", LogisticRegression(solver=\"newton-cg\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.958933301515\n",
      "Precision score: 0.963231946437\n",
      "Recall score: 0.940696774194\n",
      "F1 score: 0.951752306589\n"
     ]
    }
   ],
   "source": [
    "#Performance measures\n",
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_ncg, X, y, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_ncg, X, y, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_ncg, X, y, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_ncg, X, y, scoring='f1', cv=10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1605,   45],\n",
       "       [  74, 1174]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_ncg, X, y, cv=10)\n",
    "confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>It doesn't change anything.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emails_pipeline_lbfgs = Pipeline([(\"vectorizer\", TfidfVectorizer(stop_words = 'english')),\n",
    "                           (\"estimator\", LogisticRegression(solver=\"lbfgs\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.958933301515\n",
      "Precision score: 0.963231946437\n",
      "Recall score: 0.940696774194\n",
      "F1 score: 0.951752306589\n"
     ]
    }
   ],
   "source": [
    "#Performance measures\n",
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_lbfgs, X, y, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_lbfgs, X, y, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_lbfgs, X, y, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_lbfgs, X, y, scoring='f1', cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1605,   45],\n",
       "       [  74, 1174]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_ncg, X, y, cv=10)\n",
    "confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Same, it doesn't change anything.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_pipeline_sag = Pipeline([(\"vectorizer\", TfidfVectorizer(stop_words = 'english')),\n",
    "                           (\"estimator\", LogisticRegression(solver=\"sag\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.958933301515\n",
      "Precision score: 0.963231946437\n",
      "Recall score: 0.940696774194\n",
      "F1 score: 0.951752306589\n"
     ]
    }
   ],
   "source": [
    "#Performance measures\n",
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_sag, X, y, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_sag, X, y, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_sag, X, y, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_sag, X, y, scoring='f1', cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1605,   45],\n",
       "       [  74, 1174]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_sag, X, y, cv=10)\n",
    "confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Same, it doesn't change anything.</p>\n",
    "<p>As we can see, changing the entropy it doesn't help us so much.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try to change the norm.\n",
    "#http://www.chioka.in/differences-between-l1-and-l2-as-loss-function-and-regularization/\n",
    "emails_pipeline_penalty = Pipeline([(\"vectorizer\", TfidfVectorizer(stop_words = 'english')),\n",
    "                           (\"estimator\", LogisticRegression(penalty=\"l1\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.939954659349\n",
      "Precision score: 0.932476186381\n",
      "Recall score: 0.927870967742\n",
      "F1 score: 0.929712958964\n"
     ]
    }
   ],
   "source": [
    "#Performance measures\n",
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_penalty, X, y, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_penalty, X, y, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_penalty, X, y, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_penalty, X, y, scoring='f1', cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1565,   85],\n",
       "       [  90, 1158]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_penalty, X, y, cv=10)\n",
    "confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>It doesn't perform better and also it doesn't decrese the number of false negatives. In this case it does worst. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_df - discard those words which have a frequency higher than 0.5\n",
    "#ngram_range - extract different n-grams, in our case extract unigrams and bigrams\n",
    "#for example a bigram is \"to be\"\n",
    "#I used these combination of two parameters because I want to see if I do not discard the stop-words and\n",
    "#make them to have a sense together with other words what will hapen in the case of emails.\n",
    "emails_pipeline_params =  Pipeline([(\"vectorizer\", TfidfVectorizer(max_df=0.5, ngram_range=(1,2))),\n",
    "                           (\"estimator\", LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.962386350078\n",
      "Precision score: 0.964455755184\n",
      "Recall score: 0.947922580645\n",
      "F1 score: 0.955955195202\n"
     ]
    }
   ],
   "source": [
    "#Performance measures\n",
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_params, X, y, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_params, X, y, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_params, X, y, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_params, X, y, scoring='f1', cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1606,   44],\n",
       "       [  65, 1183]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_params, X, y, cv=10)\n",
    "confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The conclusion is that this fact doesn't make a big difference in the score.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now let's a look at the C parameter of LogisticRegression.</p>\n",
    "<p>C parameter represents the inverse of regularization strength. If C is smaller the regularization is stronger.</p>\n",
    "<p>But what it means? I find different sources which explains better than me:<a href = \"https://stats.stackexchange.com/questions/31066/what-is-the-influence-of-c-in-svms-with-linear-kernel\"> here </a> and <a href =\"https://www.quora.com/What-is-regularization-in-machine-learning\">  here </a>.But what I understand is it decides how much freedom the model has.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_pipeline_c1 =  Pipeline([(\"vectorizer\", TfidfVectorizer(stop_words='english')),\n",
    "                           (\"estimator\", LogisticRegression(C=10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.976533826512\n",
      "Precision score: 0.978170193793\n",
      "Recall score: 0.967141935484\n",
      "F1 score: 0.972585894784\n"
     ]
    }
   ],
   "source": [
    "#Performance measures\n",
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c1, X, y, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c1, X, y, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c1, X, y, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c1, X, y, scoring='f1', cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1623,   27],\n",
       "       [  41, 1207]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_c1, X, y, cv=10)\n",
    "confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As we notice the prediction is getting better.</p> \n",
    "<p>Why?Comparing with email_pipeline_sw, I notice that the number of correct predictions increseases because increasing the C it is trying to separate as many as instances possible. Imagine like you have two teams: the red ones and the blue ones. Some of reds\n",
    "are in blue team by mistake and the same for the blues. Now I am trying to find a line which give me the possibility to separe these teams better.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_pipeline_c2 =  Pipeline([(\"vectorizer\", TfidfVectorizer(stop_words='english')),\n",
    "                           (\"estimator\", LogisticRegression(C=100))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.979642047488\n",
      "Precision score: 0.982260746495\n",
      "Recall score: 0.97035483871\n",
      "F1 score: 0.976212968561\n"
     ]
    }
   ],
   "source": [
    "#Performance measures\n",
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c2, X, y, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c2, X, y, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c2, X, y, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c2, X, y, scoring='f1', cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1628,   22],\n",
       "       [  37, 1211]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_c2, X, y, cv=10)\n",
    "confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Increasing the number of C gives a better classifier.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try a simple TfidfVectorizer() and with the same C number\n",
    "emails_pipeline_c3 =  Pipeline([(\"vectorizer\", TfidfVectorizer()),\n",
    "                           (\"estimator\", LogisticRegression(C=100))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.981022551008\n",
      "Precision score: 0.979274972871\n",
      "Recall score: 0.976767741935\n",
      "F1 score: 0.977951068263\n"
     ]
    }
   ],
   "source": [
    "#Performance measures\n",
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c3, X, y, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c3, X, y, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c3, X, y, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c3, X, y, scoring='f1', cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1624,   26],\n",
       "       [  29, 1219]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_c3, X, y, cv=10)\n",
    "confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>It does a bit better if I did not discard the stop-words.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's introduce another parameter\n",
    "#Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf) \n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "emails_pipeline_c2 =  Pipeline([(\"vectorizer\", TfidfVectorizer(sublinear_tf=True)),\n",
    "                           (\"estimator\", LogisticRegression(C=100))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.985164061568\n",
      "Precision score: 0.982587468614\n",
      "Recall score: 0.983174193548\n",
      "F1 score: 0.982779762222\n"
     ]
    }
   ],
   "source": [
    "#Performance measures\n",
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c2, X, y, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c2, X, y, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c2, X, y, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c2, X, y, scoring='f1', cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1628,   22],\n",
       "       [  21, 1227]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_c2, X, y, cv=10)\n",
    "confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The classifier it is getting better. Now the number of false negatives and false positives are equaly(when I ran).</p>\n",
    "<p>Probably this parameter it helps us because of the log function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#increase the number of C\n",
    "emails_pipeline_c4 =  Pipeline([(\"vectorizer\", TfidfVectorizer(sublinear_tf=True)),\n",
    "                           (\"estimator\", LogisticRegression(C=100000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.987577854671\n",
      "Precision score: 0.988144451713\n",
      "Recall score: 0.983174193548\n",
      "F1 score: 0.985539501354\n"
     ]
    }
   ],
   "source": [
    "#Performance measures\n",
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c4, X, y, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c4, X, y, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c4, X, y, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c4, X, y, scoring='f1', cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1635,   15],\n",
       "       [  21, 1227]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_c4, X, y, cv=10)\n",
    "confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> The new classifier decreases the number of false positives. This gives you more details about our dataset. Some hams are almost similary with spams. We should do something else in this case.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#increase the number of C\n",
    "emails_pipeline_c5 =  Pipeline([(\"vectorizer\", TfidfVectorizer(sublinear_tf=True)),\n",
    "                           (\"estimator\", LogisticRegression(C=10000000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.987577854671\n",
      "Precision score: 0.988144451713\n",
      "Recall score: 0.983174193548\n",
      "F1 score: 0.985539501354\n"
     ]
    }
   ],
   "source": [
    "#Performance measures\n",
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c5, X, y, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c5, X, y, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c5, X, y, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c5, X, y, scoring='f1', cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1635,   15],\n",
       "       [  21, 1227]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_c5, X, y, cv=10)\n",
    "confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>I think we should stop here with increasing the number of C.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>CountVectorizer pipelines</h1>\n",
    "<p> Now we will look at some pipelines which are similary with those seen until now, but instead of using TfidfVectorizer I am using CountVectorizer.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_pipeline_cv_original = Pipeline([(\"vectorizer\", CountVectorizer()),\n",
    "                           (\"estimator\", LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.979646820189\n",
      "Precision score: 0.976299491394\n",
      "Recall score: 0.976787096774\n",
      "F1 score: 0.976401048836\n"
     ]
    }
   ],
   "source": [
    "#Performance measures\n",
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_cv_original, X_original, y_original, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_cv_original, X_original, y_original, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_cv_original, X_original, y_original, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_cv_original, X_original, y_original, scoring='f1', cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1620,   30],\n",
       "       [  29, 1219]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_cv_original, X_original, y_original, cv=10)\n",
    "confusion_matrix(y_original, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Without deleting information from the beginning it does better than TfidfVectorizer pipeline. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple pipeline, without parameters\n",
    "emails_pipeline_cv = Pipeline([(\"vectorizer\", CountVectorizer()),\n",
    "                           (\"estimator\", LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.97999284095\n",
      "Precision score: 0.976315096997\n",
      "Recall score: 0.977574193548\n",
      "F1 score: 0.976834748508\n"
     ]
    }
   ],
   "source": [
    "#Performance measures\n",
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_cv, X, y, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_cv, X, y, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_cv, X, y, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_cv, X, y, scoring='f1', cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1620,   30],\n",
       "       [  28, 1220]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_cv, X, y, cv=10)\n",
    "confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As we can notice it performs better as TdifVectorizer. And the number of false negatives and false positives are approximately the same. Also we can notice that it does a bit better than previous pipeline.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's drop the stop-words\n",
    "emails_pipeline_sw1 = Pipeline([(\"vectorizer\", CountVectorizer(stop_words='english')),\n",
    "                           (\"estimator\", LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.974467247345\n",
      "Precision score: 0.968116092839\n",
      "Recall score: 0.973548387097\n",
      "F1 score: 0.970541904852\n"
     ]
    }
   ],
   "source": [
    "#Performance measures\n",
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_sw1, X, y, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_sw1, X, y, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_sw1, X, y, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_sw1, X, y, scoring='f1', cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1609,   41],\n",
       "       [  33, 1215]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_sw1, X, y, cv=10)\n",
    "confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> It has a little significant difference in the score, but the number of false negatives is less than the number of false positives. It predicts more spams as hams which is not so bad.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's try another entropy\n",
    "emails_pipeline_ncg_cv = Pipeline([(\"vectorizer\", CountVectorizer(stop_words='english')),\n",
    "                           (\"estimator\", LogisticRegression(solver='newton-cg'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.973084357475\n",
      "Precision score: 0.967336145529\n",
      "Recall score: 0.971129032258\n",
      "F1 score: 0.968884328241\n"
     ]
    }
   ],
   "source": [
    "#Performance measures\n",
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_ncg_cv, X, y, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_ncg_cv, X, y, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_ncg_cv, X, y, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_ncg_cv, X, y, scoring='f1', cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1608,   42],\n",
       "       [  36, 1212]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_ncg_cv, X, y, cv=10)\n",
    "confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As we have seen at TfidVectorizer, it doesn't change anything.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline using count vectorizer\n",
    "emails_pipeline_params_cv = Pipeline([(\"vectorizer\", CountVectorizer(max_df=0.5, ngram_range=(1,2))),\n",
    "                           (\"estimator\", LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.977575468321\n",
      "Precision score: 0.969372849003\n",
      "Recall score: 0.979174193548\n",
      "F1 score: 0.974134290102\n"
     ]
    }
   ],
   "source": [
    "#Performance measures\n",
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_params_cv, X, y, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_params_cv, X, y, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_params_cv, X, y, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_params_cv, X, y, scoring='f1', cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1611,   39],\n",
       "       [  26, 1222]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_params_cv, X, y, cv=10)\n",
    "confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>It does a bit better than if I discard the stop_words.</p> Probably some words have a meaning which help us to separate better between spam and hams. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline using count vectorizer\n",
    "emails_pipeline_c_cv = Pipeline([(\"vectorizer\", CountVectorizer(stop_words='english')),\n",
    "                           (\"estimator\", LogisticRegression(C=10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.973429185061\n",
      "Precision score: 0.967167618228\n",
      "Recall score: 0.971935483871\n",
      "F1 score: 0.969299193884\n"
     ]
    }
   ],
   "source": [
    "#Performance measures\n",
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c_cv, X, y, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c_cv, X, y, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c_cv, X, y, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c_cv, X, y, scoring='f1', cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1608,   42],\n",
       "       [  35, 1213]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_c_cv, X, y, cv=10)\n",
    "confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>It does not so better as TfidfVectorizer when I increase the C.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pipeline using count vectorizer\n",
    "emails_pipeline_c1_cv = Pipeline([(\"vectorizer\", CountVectorizer(stop_words='english')),\n",
    "                           (\"estimator\", LogisticRegression(C=10000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.970329316311\n",
      "Precision score: 0.964671594346\n",
      "Recall score: 0.96715483871\n",
      "F1 score: 0.965659830653\n"
     ]
    }
   ],
   "source": [
    "#Performance measures\n",
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c1_cv, X, y, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c1_cv, X, y, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c1_cv, X, y, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_c1_cv, X, y, scoring='f1', cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1605,   45],\n",
       "       [  41, 1207]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_c1_cv, X, y, cv=10)\n",
    "confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_pipeline_params_c_cv = Pipeline([(\"vectorizer\", CountVectorizer(max_df=0.5, ngram_range=(1,2))),\n",
    "                           (\"estimator\", LogisticRegression(C=10000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.972051067892\n",
      "Precision score: 0.959411051386\n",
      "Recall score: 0.976767741935\n",
      "F1 score: 0.967868544657\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_params_c_cv, X, y, scoring='accuracy', cv=10)))\n",
    "print(\"Precision score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_params_c_cv, X, y, scoring='precision', cv=10)))\n",
    "print(\"Recall score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_params_c_cv, X, y, scoring='recall', cv=10)))\n",
    "print(\"F1 score:\",np.mean(cross_val_score\\\n",
    "                                 (emails_pipeline_params_c_cv, X, y, scoring='f1', cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1598,   52],\n",
       "       [  29, 1219]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "y_predicted = cross_val_predict(emails_pipeline_params_c_cv, X, y, cv=10)\n",
    "confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96687149504832348"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#without stratification\n",
    "#I tried also K-Fold without stratification to justify better my decision to work only with K-Fold stratified.\n",
    "kf = KFold(n_splits = 10)\n",
    "\n",
    "np.mean(cross_val_score(emails_pipeline_simple, X, y, scoring='accuracy', cv=kf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Results </h1>\n",
    "<ul>\n",
    "    <li> When I create only a simple pipeline (TfidfVectorizer(CountVectorizer)+LogisticRegression) CountVectorizer does better than TfidfVectorizer. Probably if we don't penalize the words which appears more frequently in a document it helps us to classify better spams from hams.</li>\n",
    "    <li> Also, we can notice that in the case of CountVectorizer I have a number of false negatives lower than in case of TdifdVectorizer.I think that some of the hams are similar with some of the spams, probably they have common words which in case of TfidfVectorizer they are getting penalized.</li>\n",
    "    <li> But, as we have seen, I improved TfidfVectorizer pipelines by adding some parameters which means that these pipelines reach a score of 98% which is better and also the number of false positives and false negatives are almost equal.</li>\n",
    "    <li> Another idea was to delete those lines which contain information about emails and to keep only the content. In this case our scores are better than if you keep these lines.Why? I think we should compare only the content, because this is more relevant in our case.(spam detection).</li>\n",
    "    <li> Overall, if you compare with the majority class classifier, all the classifier have a good precision.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Conclusions</h1>\n",
    "<p>In conclusion, the last TfidfVectorizer pipeline does better than all I tried until now. </p>\n",
    "<p>I demonstrated that by changing some values of parameters and adding them to pipeline, it help us to get a better pipeline.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
